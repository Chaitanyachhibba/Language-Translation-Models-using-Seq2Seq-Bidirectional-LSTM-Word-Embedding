{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\"> LANGUAGE TRANSLATION </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translates from English to French\n",
    "\n",
    "### Models\n",
    "In this section, 4 different models have been used.\n",
    "\n",
    " - Model 1 is a simple LSTM\n",
    " - Model 2 is a LSTM with Embedding\n",
    " - Model 3 is a Bidirectional LSTM with Embedding\n",
    " - <b><h3 style=\"color:red;\">Model 4 is an <U>Encoder-Decoder LSTM </U> with Bidirectional LSTM and Embedding </h3></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, TimeDistributed, Activation, RepeatVector\n",
    "from tensorflow.keras.layers import Bidirectional, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7372667322577924378\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4963368960\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10027432836746122393\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences  = load_data('small_vocab_en.txt')\n",
    "french_sentences  = load_data('small_vocab_fr.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sample 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "French sample 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "\n",
      "English sample 2:  the united states is usually chilly during july , and it is usually freezing in november .\n",
      "French sample 2:  les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "\n",
      "English sample 3:  california is usually quiet during march , and it is usually hot in june .\n",
      "French sample 3:  california est généralement calme en mars , et il est généralement chaud en juin .\n",
      "\n",
      "English sample 4:  the united states is sometimes mild during june , and it is cold in september .\n",
      "French sample 4:  les états-unis est parfois légère en juin , et il fait froid en septembre .\n",
      "\n",
      "English sample 5:  your least liked fruit is the grape , but my least liked is the apple .\n",
      "French sample 5:  votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sample_i in range(5):\n",
    "    print('English sample {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
    "    print('French sample {}:  {}\\n'.format(sample_i + 1, french_sentences[sample_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1823250 English words.\n",
      "227 unique English words.\n",
      "10 Most common words in the English dataset:\n",
      "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n",
      "\n",
      "1961295 French words.\n",
      "355 unique French words.\n",
      "10 Most common words in the French dataset:\n",
      "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"
     ]
    }
   ],
   "source": [
    "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
    "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
    "\n",
    "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
    "print('{} unique English words.'.format(len(english_words_counter)))\n",
    "print('10 Most common words in the English dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print('{} French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n",
    "print('{} unique French words.'.format(len(french_words_counter)))\n",
    "print('10 Most common words in the French dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "\n",
    "For this project, we will convert the text into sequences of integers using the following preprocess methods:\n",
    "\n",
    "Tokenize the words into ids\n",
    "Add padding to make all the sequences the same length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    \"\"\"\n",
    "    Tokenize x\n",
    "    :param x: List of sentences/strings to be tokenized\n",
    "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    return tokenizer.texts_to_sequences(x), tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n"
     ]
    }
   ],
   "source": [
    "# Tokenize Example output\n",
    "text_sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog .',\n",
    "    'By Jove , my quick study of lexicography won a prize .',\n",
    "    'This is a short sentence .']\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 4, 5, 6, 7, 1, 8, 9],\n",
       " [10, 11, 12, 2, 13, 14, 15, 16, 3, 17],\n",
       " [18, 19, 3, 20, 21]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "  Input:  The quick brown fox jumps over the lazy dog .\n",
      "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
      "Sequence 2 in x\n",
      "  Input:  By Jove , my quick study of lexicography won a prize .\n",
      "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
      "Sequence 3 in x\n",
      "  Input:  This is a short sentence .\n",
      "  Output: [18, 19, 3, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print(f'Sequence {sample_i + 1} in x')\n",
    "    print(f'  Input:  {sent}')\n",
    "    print(f'  Output: {token_sent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding \n",
    "\n",
    "When batching the sequence of word ids together, each sequence needs to be the same length. Since sentences are dynamic in length, we can add padding to the end of the sequences to make them the same length.\n",
    "\n",
    "Make sure all the English sequences have the same length and all the French sequences have the same length by adding padding to the end of each sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "  Input:  [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
      "  Output: [1 2 4 5 6 7 1 8 9 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Sequence 2 in x\n",
      "  Input:  [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
      "  Output: [10 11 12  2 13 14 15 16  3 17  0  0  0  0  0  0  0  0  0  0]\n",
      "Sequence 3 in x\n",
      "  Input:  [18, 19, 3, 20, 21]\n",
      "  Output: [18 19  3 20 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "def pad(x, length=20):\n",
    "    \"\"\"\n",
    "    Pad x\n",
    "    :param x: List of sequences.\n",
    "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
    "    :return: Padded numpy array of sequences\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    return pad_sequences(x, maxlen=length, padding='post')\n",
    "\n",
    "\n",
    "# Pad Tokenized output\n",
    "test_pad = pad(text_tokenized)\n",
    "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
    "    print(f'Sequence {sample_i + 1} in x')\n",
    "    print(f'  Input:  {token_sent}')\n",
    "    print(f'  Output: {pad_sent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Pipeline\n",
    " - Combines Tokenizing  & Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    Preprocess x and y\n",
    "    :param x: Feature List of sentences\n",
    "    :param y: Label List of sentences\n",
    "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
    "    \"\"\"\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n",
      "Max English sentence length: 20\n",
      "Max French sentence length: 20\n",
      "English vocabulary size: 199\n",
      "French vocabulary size: 344\n"
     ]
    }
   ],
   "source": [
    "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
    "    preprocess(english_sentences, french_sentences)\n",
    "    \n",
    "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
    "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
    "english_vocab_size = len(english_tokenizer.word_index)\n",
    "french_vocab_size = len(french_tokenizer.word_index)\n",
    "\n",
    "print('Data Preprocessed')\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)\n",
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"French vocabulary size:\", french_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137860, 20)\n",
      "(137860, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "print(preproc_english_sentences.shape)\n",
    "print(preproc_french_sentences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "# The neural network will be translating the input to words ids, which isn't the final form we want. \n",
    "#  We want the French translation. The function logits_to_text will bridge the gab between the logits from the neural network\n",
    "#  to the French translation. We'll be using this function to better understand the output of the neural network.\n",
    "\n",
    "def logits_to_text(logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    #index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words =  tokenizer.index_word\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "print('`logits_to_text` function loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a basic RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.005\n",
    "    \n",
    "    # TODO: Build the layers\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=input_shape[1:], return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137860, 20)\n",
      "(137860, 20)\n",
      "(137860, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reshaping the input to work with a basic RNN\n",
    "print(preproc_english_sentences.shape)\n",
    "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
    "print(tmp_x.shape)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))\n",
    "print(tmp_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 20, 256)           264192    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 20, 1024)          263168    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 1024)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 20, 344)           352600    \n",
      "=================================================================\n",
      "Total params: 879,960\n",
      "Trainable params: 879,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the neural network\n",
    "simple_rnn_model = simple_model(\n",
    "    tmp_x.shape,\n",
    "    max_french_sequence_length,\n",
    "    english_vocab_size,\n",
    "    french_vocab_size)\n",
    "\n",
    "print(simple_rnn_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(simple_rnn_model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110288 samples, validate on 27572 samples\n",
      "Epoch 1/10\n",
      "110288/110288 [==============================] - 9s 79us/sample - loss: 2.0627 - accuracy: 0.5142 - val_loss: nan - val_accuracy: 0.6150\n",
      "Epoch 2/10\n",
      "110288/110288 [==============================] - 6s 52us/sample - loss: 1.2799 - accuracy: 0.6257 - val_loss: nan - val_accuracy: 0.6659\n",
      "Epoch 3/10\n",
      "110288/110288 [==============================] - 6s 53us/sample - loss: 1.1269 - accuracy: 0.6549 - val_loss: nan - val_accuracy: 0.6807\n",
      "Epoch 4/10\n",
      "110288/110288 [==============================] - 6s 53us/sample - loss: 1.0348 - accuracy: 0.6713 - val_loss: nan - val_accuracy: 0.6951\n",
      "Epoch 5/10\n",
      "110288/110288 [==============================] - 6s 54us/sample - loss: 0.9773 - accuracy: 0.6804 - val_loss: nan - val_accuracy: 0.6965\n",
      "Epoch 6/10\n",
      "110288/110288 [==============================] - 6s 53us/sample - loss: 0.9334 - accuracy: 0.6898 - val_loss: nan - val_accuracy: 0.7190\n",
      "Epoch 7/10\n",
      "110288/110288 [==============================] - 6s 55us/sample - loss: 0.8867 - accuracy: 0.7011 - val_loss: nan - val_accuracy: 0.7300\n",
      "Epoch 8/10\n",
      "110288/110288 [==============================] - 6s 55us/sample - loss: 0.8468 - accuracy: 0.7140 - val_loss: nan - val_accuracy: 0.7203\n",
      "Epoch 9/10\n",
      "110288/110288 [==============================] - 6s 55us/sample - loss: 0.8009 - accuracy: 0.7290 - val_loss: nan - val_accuracy: 0.7502\n",
      "Epoch 10/10\n",
      "110288/110288 [==============================] - 6s 54us/sample - loss: 0.7664 - accuracy: 0.7409 - val_loss: nan - val_accuracy: 0.7689\n",
      "new jersey est parfois chaud en mois de il et il est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Print prediction(s)\n",
    "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "new jersey est parfois chaud en mois de il et il est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "Correct Translation:\n",
      "[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"]\n",
      "\n",
      "Original text:\n",
      "['new jersey is sometimes quiet during autumn , and it is snowy in april .']\n"
     ]
    }
   ],
   "source": [
    "# Print prediction(s)\n",
    "print(\"Prediction:\")\n",
    "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))\n",
    "\n",
    "print(\"\\nCorrect Translation:\")\n",
    "print(french_sentences[:1])\n",
    "\n",
    "print(\"\\nOriginal text:\")\n",
    "print(english_sentences[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 2\n",
    "\n",
    "### - Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a RNN model using word embedding on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.005\n",
    "    \n",
    "    # TODO: Build the layers\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(english_vocab_size, 256, input_length=input_shape[1], input_shape=input_shape[1:]))\n",
    "    model.add(LSTM(256, return_sequences=True))    \n",
    "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 256)           51200     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 20, 256)           525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 1024)          263168    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 1024)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 20, 345)           353625    \n",
      "=================================================================\n",
      "Total params: 1,193,305\n",
      "Trainable params: 1,193,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: Reshape the input\n",
    "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))\n",
    "\n",
    "# TODO: Train the neural network\n",
    "embed_rnn_model = embed_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_french_sentences.shape[1],\n",
    "    len(english_tokenizer.word_index)+1,\n",
    "    len(french_tokenizer.word_index)+1)\n",
    "\n",
    "embed_rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110288 samples, validate on 27572 samples\n",
      "Epoch 1/10\n",
      "110288/110288 [==============================] - 9s 83us/sample - loss: 1.6839 - accuracy: 0.6218 - val_loss: 0.5985 - val_accuracy: 0.8152\n",
      "Epoch 2/10\n",
      "110288/110288 [==============================] - 8s 70us/sample - loss: 0.4825 - accuracy: 0.8459 - val_loss: 0.3478 - val_accuracy: 0.8853\n",
      "Epoch 3/10\n",
      "110288/110288 [==============================] - 8s 68us/sample - loss: 0.3305 - accuracy: 0.8909 - val_loss: 0.2743 - val_accuracy: 0.9063\n",
      "Epoch 4/10\n",
      "110288/110288 [==============================] - 8s 68us/sample - loss: 0.2705 - accuracy: 0.9090 - val_loss: 0.2388 - val_accuracy: 0.9181\n",
      "Epoch 5/10\n",
      "110288/110288 [==============================] - 8s 69us/sample - loss: 0.2396 - accuracy: 0.9182 - val_loss: 0.2201 - val_accuracy: 0.9237\n",
      "Epoch 6/10\n",
      "110288/110288 [==============================] - 8s 69us/sample - loss: 0.2222 - accuracy: 0.9232 - val_loss: 0.2081 - val_accuracy: 0.9274\n",
      "Epoch 7/10\n",
      "110288/110288 [==============================] - 8s 69us/sample - loss: 0.2105 - accuracy: 0.9266 - val_loss: 0.2001 - val_accuracy: 0.9298\n",
      "Epoch 8/10\n",
      "110288/110288 [==============================] - 8s 69us/sample - loss: 0.2013 - accuracy: 0.9294 - val_loss: 0.1959 - val_accuracy: 0.9319\n",
      "Epoch 9/10\n",
      "110288/110288 [==============================] - 8s 69us/sample - loss: 0.1953 - accuracy: 0.9310 - val_loss: 0.1962 - val_accuracy: 0.9314\n",
      "Epoch 10/10\n",
      "110288/110288 [==============================] - 8s 69us/sample - loss: 0.1899 - accuracy: 0.9327 - val_loss: 0.1912 - val_accuracy: 0.9327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26505744148>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "new jersey est parfois calme en l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "Correct Translation:\n",
      "[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"]\n",
      "\n",
      "Original text:\n",
      "['new jersey is sometimes quiet during autumn , and it is snowy in april .']\n"
     ]
    }
   ],
   "source": [
    "# Print prediction(s)\n",
    "print(\"Prediction:\")\n",
    "print(logits_to_text(embed_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))\n",
    "\n",
    "print(\"\\nCorrect Translation:\")\n",
    "print(french_sentences[:1])\n",
    "\n",
    "print(\"\\nOriginal text:\")\n",
    "print(english_sentences[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Bidirectional RNNs\n",
    "\n",
    " - One restriction of a RNN is that it can't see the future input, only the past. This is where bidirectional recurrent neural networks come in. They are able to see the future data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a bidirectional RNN model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.003\n",
    "    \n",
    "    # TODO: Build the layers\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(english_vocab_size, 256, input_length=input_shape[1], input_shape=input_shape[1:]))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 20, 256)           51200     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 20, 256)           525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 20, 1024)          263168    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20, 1024)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 20, 345)           353625    \n",
      "=================================================================\n",
      "Total params: 1,193,305\n",
      "Trainable params: 1,193,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: Reshape the input\n",
    "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))\n",
    "\n",
    "# TODO: Train and Print prediction(s)\n",
    "embed_rnn_model = embed_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_french_sentences.shape[1],\n",
    "    len(english_tokenizer.word_index)+1,\n",
    "    len(french_tokenizer.word_index)+1)\n",
    "\n",
    "embed_rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110288 samples, validate on 27572 samples\n",
      "Epoch 1/10\n",
      "110288/110288 [==============================] - 25s 231us/sample - loss: 1.6978 - accuracy: 0.6175 - val_loss: 0.6224 - val_accuracy: 0.8106\n",
      "Epoch 2/10\n",
      "110288/110288 [==============================] - 24s 218us/sample - loss: 0.4984 - accuracy: 0.8419 - val_loss: 0.3534 - val_accuracy: 0.8828\n",
      "Epoch 3/10\n",
      "110288/110288 [==============================] - 25s 224us/sample - loss: 0.3411 - accuracy: 0.8867 - val_loss: 0.2869 - val_accuracy: 0.9038\n",
      "Epoch 4/10\n",
      "110288/110288 [==============================] - 25s 223us/sample - loss: 0.2768 - accuracy: 0.9066 - val_loss: 0.2378 - val_accuracy: 0.9187\n",
      "Epoch 5/10\n",
      "110288/110288 [==============================] - 25s 224us/sample - loss: 0.2436 - accuracy: 0.9167 - val_loss: 0.2197 - val_accuracy: 0.9238\n",
      "Epoch 6/10\n",
      "110288/110288 [==============================] - 24s 219us/sample - loss: 0.2239 - accuracy: 0.9225 - val_loss: 0.2107 - val_accuracy: 0.9268\n",
      "Epoch 7/10\n",
      "110288/110288 [==============================] - 24s 218us/sample - loss: 0.2104 - accuracy: 0.9263 - val_loss: 0.2039 - val_accuracy: 0.9289\n",
      "Epoch 8/10\n",
      "110288/110288 [==============================] - 24s 218us/sample - loss: 0.2018 - accuracy: 0.9288 - val_loss: 0.1967 - val_accuracy: 0.9309\n",
      "Epoch 9/10\n",
      "110288/110288 [==============================] - 24s 219us/sample - loss: 0.1946 - accuracy: 0.9309 - val_loss: 0.1920 - val_accuracy: 0.9331\n",
      "Epoch 10/10\n",
      "110288/110288 [==============================] - 24s 222us/sample - loss: 0.1897 - accuracy: 0.9323 - val_loss: 0.1912 - val_accuracy: 0.9325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2654cb034c8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "new jersey est parfois calme en l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "Correct Translation:\n",
      "[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"]\n",
      "\n",
      "Original text:\n",
      "['new jersey is sometimes quiet during autumn , and it is snowy in april .']\n"
     ]
    }
   ],
   "source": [
    "# Print prediction(s)\n",
    "print(\"Prediction:\")\n",
    "print(logits_to_text(embed_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))\n",
    "\n",
    "print(\"\\nCorrect Translation:\")\n",
    "print(french_sentences[:1])\n",
    "\n",
    "print(\"\\nOriginal text:\")\n",
    "print(english_sentences[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> Model 4: Encoder-Decoder </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  model_final (input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a model that incorporates embedding, encoder-decoder, and bidirectional RNN\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.003\n",
    "\n",
    "    # Build the layers    \n",
    "    model = Sequential()\n",
    "    # Embedding\n",
    "    model.add(Embedding(english_vocab_size, 128, input_length=input_shape[1],\n",
    "                         input_shape=input_shape[1:]))\n",
    "    # Encoder\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    # Decoder\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(512, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax')))\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 128)           25600     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 20, 256)           263168    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 20, 256)           394240    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 512)           131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20, 512)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 20, 200)           102600    \n",
      "=================================================================\n",
      "Total params: 1,311,432\n",
      "Trainable params: 1,311,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    # TODO: Train neural network using model_final\n",
    "model = model_final(preproc_english_sentences.shape,\n",
    "                    preproc_french_sentences.shape[1],\n",
    "                    len(english_tokenizer.word_index)+1,\n",
    "                    len(english_tokenizer.word_index)+1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110288 samples, validate on 27572 samples\n",
      "Epoch 1/25\n",
      "110288/110288 [==============================] - 18s 164us/sample - loss: nan - accuracy: 0.3769 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 2/25\n",
      "110288/110288 [==============================] - 10s 93us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 3/25\n",
      "110288/110288 [==============================] - 10s 93us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 4/25\n",
      "110288/110288 [==============================] - 10s 94us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 5/25\n",
      "110288/110288 [==============================] - 10s 94us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 6/25\n",
      "110288/110288 [==============================] - 10s 93us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 7/25\n",
      "110288/110288 [==============================] - 10s 93us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 8/25\n",
      "110288/110288 [==============================] - 10s 93us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 9/25\n",
      "110288/110288 [==============================] - 10s 93us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 10/25\n",
      "110288/110288 [==============================] - 10s 93us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 11/25\n",
      "110288/110288 [==============================] - 10s 93us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 12/25\n",
      "110288/110288 [==============================] - 10s 93us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 13/25\n",
      "110288/110288 [==============================] - 10s 93us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 14/25\n",
      "110288/110288 [==============================] - 10s 95us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797accuracy: 0.378 - ETA: 7s - loss: nan - accura - ETA: 6s -\n",
      "Epoch 15/25\n",
      "110288/110288 [==============================] - 10s 94us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 16/25\n",
      "110288/110288 [==============================] - 10s 93us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 17/25\n",
      "110288/110288 [==============================] - 10s 94us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 18/25\n",
      "110288/110288 [==============================] - 10s 93us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 19/25\n",
      "110288/110288 [==============================] - 10s 93us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 20/25\n",
      "110288/110288 [==============================] - 10s 93us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 21/25\n",
      "110288/110288 [==============================] - 10s 94us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797ETA: 1s - loss: nan - \n",
      "Epoch 22/25\n",
      "110288/110288 [==============================] - 10s 94us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 23/25\n",
      "110288/110288 [==============================] - 10s 93us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 24/25\n",
      "110288/110288 [==============================] - 10s 94us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n",
      "Epoch 25/25\n",
      "110288/110288 [==============================] - 10s 94us/sample - loss: nan - accuracy: 0.3786 - val_loss: nan - val_accuracy: 0.3797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x188e7b4fe08>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(preproc_english_sentences, preproc_french_sentences, batch_size=512, epochs=25, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
